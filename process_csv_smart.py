import pandas as pd
import json
import time
import sys
import os

def log_message(message):
    """Funci√≥n para logging con timestamp"""
    timestamp = time.strftime("%H:%M:%S")
    print(f"[{timestamp}] {message}")

def safe_divide(numerator, denominator, default=0):
    """Divisi√≥n segura que evita divisi√≥n por cero"""
    try:
        return numerator / denominator if denominator != 0 else default
    except:
        return default

def main():
    try:
        log_message("üöÄ Iniciando procesamiento inteligente del CSV...")
        start_time = time.time()
        
        # Verificar que el archivo existe
        csv_path = 'data/Female _GenZ_Populations.csv'
        if not os.path.exists(csv_path):
            log_message("‚ùå Error: No se encontr√≥ el archivo CSV")
            return False
        
        # Leer el archivo CSV
        log_message("üìñ Leyendo archivo CSV...")
        df = pd.read_csv(csv_path)
        
        log_message(f"‚úÖ Archivo le√≠do: {len(df):,} filas")
        
        # Validar columnas
        required_columns = ['DMA', 'Zip', 'Total Population', 'Total Female GenZ', 'GenZ Female %']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            log_message(f"‚ùå Error: Faltan columnas: {missing_columns}")
            return False
        
        # Calcular benchmark nacional
        log_message("üßÆ Calculando benchmark nacional...")
        total_population = df['Total Population'].sum()
        total_genz_females = df['Total Female GenZ'].sum()
        national_benchmark = safe_divide(total_genz_females, total_population) * 100
        
        log_message(f"üìà Benchmark Nacional: {national_benchmark:.2f}%")
        log_message(f"üë• Poblaci√≥n Total: {total_population:,}")
        log_message(f"üë© Gen Z Females: {total_genz_females:,}")
        
        # Obtener ciudades √∫nicas
        unique_dmas = df['DMA'].unique()
        log_message(f"üèôÔ∏è Ciudades √∫nicas: {len(unique_dmas)}")
        
        # Procesar datos en chunks peque√±os
        log_message("‚ö° Procesando datos en chunks...")
        dashboard_data = []
        chunk_size = 500  # Chunks m√°s peque√±os para mejor control
        total_chunks = (len(df) + chunk_size - 1) // chunk_size
        
        for i in range(0, len(df), chunk_size):
            chunk = df.iloc[i:i+chunk_size]
            current_chunk = (i // chunk_size) + 1
            
            log_message(f"üì¶ Procesando chunk {current_chunk}/{total_chunks}...")
            
            for _, row in chunk.iterrows():
                try:
                    # Calcular √≠ndice
                    zip_genz_pct = row['GenZ Female %']
                    zip_index = safe_divide(zip_genz_pct, national_benchmark) * 100
                    
                    # Calcular distribuci√≥n de edades
                    total_genz = row['Total Female GenZ']
                    age15_19_pct = safe_divide(row['2024 Females Age 15-19'], total_genz) * 100
                    age20_24_pct = safe_divide(row['2024 Females Age 20-24'], total_genz) * 100
                    age25_29_pct = safe_divide(row['2024 Females Age 25-29'], total_genz) * 100
                    
                    # Mapear regi√≥n b√°sica
                    region = "Unknown"
                    dma_str = str(row['DMA']).lower()
                    
                    if any(state in dma_str for state in ['california', 'los angeles', 'san francisco', 'san diego']):
                        region = "West Coast"
                    elif any(state in dma_str for state in ['texas', 'houston', 'dallas', 'san antonio']):
                        region = "Texas"
                    elif any(state in dma_str for state in ['florida', 'miami', 'tampa', 'orlando']):
                        region = "Florida"
                    elif any(state in dma_str for state in ['new york', 'washington', 'boston', 'philadelphia']):
                        region = "Northeast"
                    elif any(state in dma_str for state in ['chicago', 'detroit', 'minneapolis']):
                        region = "Midwest"
                    elif any(state in dma_str for state in ['atlanta', 'charlotte', 'nashville']):
                        region = "Southeast"
                    elif any(state in dma_str for state in ['denver', 'phoenix', 'salt lake']):
                        region = "Mountain West"
                    
                    dashboard_data.append({
                        'dma': str(row['DMA']),
                        'zip': str(row['Zip']),
                        'region': region,
                        'population': int(row['Total Population']),
                        'genZFemales': int(row['Total Female GenZ']),
                        'concentration': round(zip_genz_pct / 100, 4),
                        'index': round(zip_index, 1),
                        'age15_19': round(age15_19_pct, 1),
                        'age20_24': round(age20_24_pct, 1),
                        'age25_29': round(age25_29_pct, 1)
                    })
                    
                except Exception as e:
                    log_message(f"‚ö†Ô∏è Error procesando fila {i}: {str(e)}")
                    continue
            
            # Mostrar progreso
            progress = (current_chunk / total_chunks) * 100
            log_message(f"üìä Progreso: {progress:.1f}% ({len(dashboard_data):,} registros procesados)")
        
        # Calcular estad√≠sticas por DMA
        log_message("üìä Calculando estad√≠sticas por DMA...")
        dma_stats = df.groupby('DMA').agg({
            'Total Population': 'sum',
            'Total Female GenZ': 'sum',
            'GenZ Female %': 'mean'
        }).reset_index()
        
        dma_stats['Index_vs_National'] = (dma_stats['GenZ Female %'] / national_benchmark) * 100
        dma_stats = dma_stats.sort_values('Index_vs_National', ascending=False)
        
        # Guardar datos
        log_message("üíæ Guardando datos...")
        output_data = {
            'metadata': {
                'national_benchmark': round(national_benchmark, 2),
                'total_population': int(total_population),
                'total_genz_females': int(total_genz_females),
                'unique_cities': len(unique_dmas),
                'total_zip_codes': len(dashboard_data),
                'processing_time': round(time.time() - start_time, 2)
            },
            'top_cities': dma_stats.head(20).to_dict('records'),
            'data': dashboard_data
        }
        
        # Guardar archivos
        with open('real_data.json', 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        dma_stats.to_csv('dma_analysis_real.csv', index=False)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        log_message(f"\nüéâ ¬°Procesamiento completado exitosamente!")
        log_message(f"‚è±Ô∏è Tiempo total: {processing_time:.2f} segundos")
        log_message(f"üìÅ Archivos generados:")
        log_message(f"   - real_data.json ({len(dashboard_data):,} registros)")
        log_message(f"   - dma_analysis_real.csv ({len(dma_stats)} ciudades)")
        
        log_message(f"\nüìà Top 10 ciudades por √≠ndice Gen Z:")
        for i, row in dma_stats.head(10).iterrows():
            log_message(f"   {i+1:2d}. {row['DMA']:<30} | √çndice: {row['Index_vs_National']:6.1f}")
        
        return True
        
    except Exception as e:
        log_message(f"‚ùå Error cr√≠tico: {str(e)}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        log_message("‚úÖ ¬°Listo para actualizar el dashboard!")
    else:
        log_message("‚ùå Procesamiento fall√≥. Revisar errores arriba.")
        sys.exit(1)

